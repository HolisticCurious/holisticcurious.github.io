---
layout: post
title: Então sobreviveste a uma pandemia? Eis outras formas de eliminar a Humanidade
subheading: Diferencial
author: Maria Teresa Parreira
categories: published
banner: "/assets/images/banners/texto-dif.png"
tags: [future,opinion, pt]
sidebar: []
---

*Inicialmente publicado no [Diferencial](https://diferencial.tecnico.ulisboa.pt/edicao/pandemonio/entao-sobreviveste-a-uma-pandemia-eis-outras-formas-de-eliminar-a-humanidade/).*


### Diminuição dos níveis de poluição. Mais grandes empresas com compromissos de neutralidade de carbono. Alargou-se o número de países nos quais o casamento homossexual é reconhecido por lei. Se o leitor tende a olhar 2020 através de um copo meio cheio, talvez deva ficar por aqui; se, por outro lado, este ano lhe revelou quão escassa pode ser a água e quão frágil é o vidro do copo, deleite-se: entre as potenciais ameaças à Humanidade, uma pandemia é um passeio no parque.


A resposta defeituosa da sociedade e das suas formas de governo ao emergir de uma ameaça biológica que, convenhamos, impõe apenas um risco muito moderado num país desenvolvido, revelou quão pouco preparada a Humanidade está para lidar com qualquer situação que constitua uma rutura com o modo de vida aceite como normal. Medidas de mitigação do impacto da pandemia foram tomadas de forma apressada, pouco categórica e com base no melhor conhecimento existente até à data – dados em número insuficiente, modelos pouco rigorosos e análises incompletas – o que fez com que a resposta dos governos e autoridades de saúde tenha sido (e ainda seja) desordenada, inconsistente e contraditória.

**Num pestanejar, a fragilidade dos alicerces nos quais se apoia a nossa normalidade foi exposta. E notamos, sem que isso soe a pessimismo extremo: podia ter sido muito pior.** Se a pandemia acarretasse consequências um pouco mais graves, se fosse ainda mais contagiosa e a gestão dos sintomas exigisse mais recursos, rapidamente assistiríamos ao colapso total dos sistemas de saúde e economia e contemplaríamos um desenlace sem qualquer esperança de retomar velhos hábitos. A Humanidade olha para o futuro com antolhos, palas que restringem qualquer campo de visão que não tenha como objetivo a prosperidade económica e isso faz com que caminhemos sobre chão instável, precário, insustentável. E, já que estabelecemos para esta reflexão um tom pessimista, não fiquemos por aqui – uma pandemia está longe de ser o único risco atual que enfrentamos enquanto sociedade e como espécie. Felizmente, grandes mentes já recolheram e organizaram informação de forma categórica sobre o que pode ameaçar a nossa existência. Agarrem-se às vossas insónias e embarquemos numa atribulada jornada de contemplações derrotistas.

**O [_Future of Life Institute (FLI)_](https://futureoflife.org/) é um instituto de investigação sem fins lucrativos criado em 2014 que analisa e trabalha para mitigar os potenciais riscos para a nossa existência que possam provir de desenvolvimentos tecnológicos, garantindo que o progresso é atingido com a condicional de ser benéfico para a Humanidade.** 
Não se trata de pseudociência, contando com fundadores como Jaan Tallinn (co-fundador do Skype) e Max Tegmark (professor no MIT) e tendo o apoio de inúmeras outras personalidades
nos campos da física, genética e inteligência artificial. Esta é, porém, apenas uma das muitas instituições de foro académico que se dedicam a este tópico 
(talvez a mais mediática por contar com o apoio de Elon Musk): a Universidade de Cambrige possui o [_Centre for the Study of Existencial Risk_(CSER)](https://www.cser.ac.uk/about-us/); Oxford investe no 
[_Future of Humanity Institute (FHI)_](https://www.fhi.ox.ac.uk/).

Num [artigo de 2002](https://nickbostrom.com/existential/risks.html), Nick Bostrom, diretor do FHI e consultor para o FLI, define _riscos existenciais_ como “eventos cujo efeito seja global e a intensidade seja terminal”, 
isto é, eventos com a potencialidade de eliminar ou danificar de forma irreversível o potencial de vida da totalidade da Humanidade, e divide os mesmos em 4 categorias: 
_bangs_ (extinção súbita de toda a vida inteligente na Terra, provocada por um acidente ou ato deliberado de destruição), _crunches_ (a espécie humana tem continuidade mas o
potencial de evolução da mesma para uma “pós-humanidade” fica permanentemente impedido), _shrieks_ (a “pós-humanidade” é atingida mas extremamente condicionada) e _whimpers_
(a “pós-humanidade” subsiste mas evolui de uma forma que leva ao desaparecimento irrevogável do que valorizamos). Mergulhemos sobre cada uma destas categorias numa espiral 
descendente de otimismo.

_Whimpers_ incluem cenários como uma invasão levada a cabo por uma população extraterrestre hostil ou a evolução genética da espécie humana (que, atualmente, é bastante lenta por ser condicionada por processos naturais mas que no futuro, com o desenvolvimento de tecnologia genética e computacional, poderá ser acelerada) para algo que torna insustentável ou irreconhecível a nossa existência.

_Shrieks_ envolvem a noção de _upload_ – a transferência da “mente” humana de um cérebro biológico para um computador, conservando todas as suas memórias, carácter e valores. 
Tal desenvolvimento tecnológico permitiria aperfeiçoar o nosso processo de aprendizagem e aquisição de conhecimento devido ao rápido acesso a nova informação, no que se tornaria
um _loop_ com _feedback_ positivo, potenciando melhoramentos futuros através dos atuais. Podemos imaginar como esta capacidade faria explodir o potencial de progresso
tecnológico; porém, _uploads_ que atinjam um elevado patamar de inteligência poderiam rapidamente desenvolver a capacidade de impedir outros _uploads_ de se formarem, 
impondo os seus interesses e opiniões sobre o bem-maior. Um cenário parecido protagoniza uma superinteligência inadequadamente programada que implemente medidas erróneas 
por acidente e atinja rapidamente domínio sobre a Humanidade. Se esta superinteligência fosse inicialmente desenvolvida por grupos com ideias extremistas ou totalitárias,
esses objetivos enviesados poderiam alterar o comportamento do programa quando este fugisse ao controlo humano e o caos suceder-se-ia.

_Crunches_ podem ter como origem o esgotamento de recursos ou destruição ecológica, minando qualquer progresso tecnológico atualmente atingido. Um cenário mais criativo 
refere o emergir de uma forma de governo fundamentalista e extremista cuja autoridade seja conseguida através de vigilância avançada ou mesmo controlo mental, condicionando 
o nosso comportamento e progresso aos valores desejados por um pequeno grupo de pessoas no poder, cujo objetivo pode incluir travar ou involuir o progresso da Humanidade. 
Por outro lado, a partir de evidências que correlacionam negativamente fertilidade com realizações/feitos intelectuais, seria possível que pressões de seleção natural
produzissem, a longo prazo, uma evolução da espécie _homo sapiens_ para _homo philoprogenitus (“lover of many offspring”)_, ameaçando desta forma o ritmo de desenvolvimento
tecnológico devido à diminuição da nossa capacidade intelectual.

Por fim, _bangs_ surgem como a perspetiva mais devastadora e, contudo, conceptualmente mais simples. Utilização deliberadamente prejudicial de nanotecnologia – o que pode 
incluir nanorobots auto-replicativos, com capacidade para destruir a biosfera por vias de contaminação, ou bloqueio permanente da luz solar. Um holocausto nuclear também 
surge como perspetiva, tendo em conta o potencial devastador deste tipo de armas e a falta de conhecimento sobre o seu impacto climático. 

Num campo mais imaginativo, a velha hipótese de que somos o produto de uma simulação é recuperada e a extinção da Humanidade seria uma mera consequência da decisão de desligar
o computador. O cenário da má programação de uma entidade de superinteligência, já mencionado, poderia rapidamente pôr um fim à nossa existência. Uma outra via de destruição, 
acidental ou deliberada, pode passar pelo desenvolvimento de agentes biológicos geneticamente modificados de elevado contágio e mortalidade. Estes agentes podem ser usados 
como armas mas a sua libertação acidental também é possível, e a medicina e tecnologia atuais não possuem a capacidade de lidar com as implicações de tal evento.

Impacto de um asteroide ou cometa; aquecimento global a evoluir a um ritmo demasiado acelerado para a nossa capacidade de resposta; supernovas, explosões solares, supervulcões. Terminemos a enumeração com a categoria “desastres físicos”: por exemplo, uma experiência num acelerador de partículas de elevada energia que cause um “vácuo” que se expandiria numa bolha de destruição total, ou um mini-buraco negro. E não nos esqueçamos de mencionar qualquer outra circunstância que o nosso conhecimento atual não permite prever sequer como possível – um indireto apelo à criatividade do leitor para imaginar cenários não descritos aqui.

Na sequência destes parágrafos, um indivíduo pragmático proferirá mentalmente “alerta noção”. A verdade é que todos os riscos foram enunciados com igual destaque e sem nenhuma menção de um dos pontos mais importantes para a discussão – a probabilidade da sua ocorrência. Tendo em conta o nosso conhecimento atual, afirmar com absoluta certeza que qualquer um destes eventos é impossível seria irresponsável; contudo, **os esforços da Humanidade no sentido de tomar medidas preventivas devem ser focados nos riscos que são mensuravelmente mais plausíveis e cuja origem ou cujo horizonte temporal indiciam que ações de preparação e minimização de efeitos serão eficientes.

Tendo em conta o que está em risco no pior desenlace – a extinção da Humanidade – a abordagem não pode ser reativa, de tentativa e erro (algo que tem acontecido na atual pandemia) mas sim, como sugere Bostrom, proativa, desenvolvendo ferramentas que permitam antecipar este tipo de acontecimentos e adotar medidas assertivas de prevenção. Tratando-se de ameaças a toda a espécie, divisões artificiais como nações ou tendências políticas devem ser postas de lado na tomada de decisões, sem que isto isente qualquer país da sua responsabilidade em ser parte da solução. **A tolerância demonstrada atualmente da parte de diversas instituições a países que não cumprem as metas climáticas é exatamente um exemplo de desleixo contraproducente que não só dificulta a prevenção como pode mesmo potenciar a ocorrência de eventos no leque dos riscos existenciais.** Outro fator que deve pesar para aqueles que decidem se é ou não a altura de tomar medidas: o impacto das mesmas não se restringe aos atuais 7.8 mil milhões de indivíduos percorrendo esta Terra, mas sim a todos os futuros espécimes humanos, elevando a importância da nossa ação presente.

Não nos percamos, no entanto, com reflexões moralistas. Eis uma lista de circunstâncias que ameaçam a nossa existência como a conhecemos e eis como estamos completamente impotentes perante a maior parte das mesmas. 10 minutos de leitura que o leitor nunca recuperará.

